# 生成AI（LLM）利活用ドキュメント
これは筆者が業務や個人開発などを通じて得た所感・情報をまとめたドキュメントになります。<br>
業務や個人開発、技術の試用検証などを通じて得た所感や知見を、その時その時の記事にまとめていたのですが、散らばってきた感が出てきたので一つの記事にまとめようと思いました。<br>

現段階（2025/11）での生成AI（LLM）利活用における筆者の結論としては、 **AIが進化するほど「設計力」「問題把握・想起力」「論理的思考に基づく言語化能力」「抽象・具体の柔軟な思考切り替え」が人間側の差別化要素となる**という考えです。

## はじめに
生成AI（LLM）は、設計、開発、情報整理など幅広い分野で活用されています。<br>
特に近年では Vibe Coding や仕様駆動開発、AI駆動開発といった、AIが自律的に支援・主導するスタイルが注目されています。<br>

> [!NOTE]
> Vibe Coding： AIがコードを自動生成し、開発者は自然言語で指示を出すだけで開発できる手法を指す

現状の業界トレンドとして、Claudeなど各種AI（LLM）を最良活用するために**ユーザー（開発者）の目的とする成果物を生成できるようなルール設定を試行錯誤し合っている状況**だと感じています。<br>
`AGENTS.md`, `copilot-instructions.md`などのメタ設定ファイルは、**AIに人間側の意図を汲み取らせるためのレール**であり、**最適なレールの敷き方（ベストプラクティス）を模索している段階**にあるとも思っています。<br>

こうした流れの中で筆者は次のように感じています。

- コード実装力や実装速度よりも、設計力など上流工程に関するスキルが重要になってくる
- AIの成果物をチェックするための（言語や仕様、フレームワーク、ライブラリなど）基礎知識
- 基礎知識に基づく（専門用語を盛り込むなどの）適切なプロンプトをつくるための言語化能力と論理的思考力
- 抽象・具体の柔軟な思考切り替え
  - 抽象化能力：課題や情報、概念、アイデアといった取り組む対象の本質を捉えるために必要
  - 具体化能力：本質を言語化したり、根本的解決の直接的・間接的要因を閃いたり、具体的なアプローチ方法に落とし込んだりするために必要

<details>
<summary>余談</summary>

ちなみに、、極力無料主義の筆者的には、汎用化かつ拡張された無料AIツールの到来を期待しつつ、その時が来れば十分に活用できるよう情報収集と慣れを重ねておくべきとも考えています。<br>

これは「現状、**AIに関する形式知と暗黙知を蓄積**する戦略を採っていきたい」という考えがあり、**（自分たちにとって）適切な使用イメージを掴むためには汎用性のある知見（形式知と暗黙知）の充実**が大事になってくると思っているためです。<br>

例えば、「パソコン（またはスマホ）を使って何かして」と言われれば現代人は調べ物をしたり、資料作成など仕事に用いたりするといった使用イメージを苦もなく描けるはずです。<br>
その理由は、多くの人がデジタルデバイスの利用が当たり前となって形式知と暗黙知が充分にあるからです。<br>

この点はAIも同じだと思います。

</details>

そして、この先は **ものごと（例：未知の課題やビジネスアイデアなど）へのアプローチを考える「問題把握力と問題想起力」がより重要** となるのでは？と考えています。<br>
人と人とのコミュニケーションが必要な部分以外においては、課題解決力など実務面はAIが担っていくと考えられるので、**人はものごと及びそれへのアプローチを考える役割が強く**なりそうだと。<br>
先に述べた問題把握力と問題想起力とは、課題解決における**方針や仮説出し、アプローチ方法の選定など上流工程部分に関わってくるようなもの**、と想定しています。<br>

具体的には以下です。

- **問題把握力**<br>
どこにどんな問題があるかのアタリを付ける（仮説を出してアプローチ範囲を設定する）
- **問題想起力**<br>
何がペインまたはボトルネックかを考える

上記のような「問題の切り分け方法」といったエンジニアリング以外に関する事柄については以下の記事が参照になりました。<br>

https://zenn.dev/arsaga/articles/3c3b16a315444f

そして、今後スタンダードとなるAIを活用した働き方（AIとの協業）においては、以下の「基礎知識」と「AI活用の知見」が重要となると考えています。<br>
例えば、これまでの「Pythonを学ぶ」や「Nextを使ってトレンドに追従」という基礎学習となる部分に加えて、AI活用の学習が必要となるので**学ぶ量が倍増する**と思いますorz。<br>

- 基礎知識
    - サイトが表示される仕組みや通信などWeb・インターネットに関する土台となるような部分
    - JavaScript（TypeScript）, Python, Go, PHP といった言語
    - React/Next, Vue/Nuxt, Django, Flask , Laravel などのフレームワークの学習
    - AIが生成したコードの安全性をチェックするためのセキュリティ関連の知識
- AI活用の知見
    - プロンプトエンジニアリング（※進歩の仕方によっては不要となるかも）
    - 各種生成AI（LLM）の特徴（例えば、検索系はPerplexityとか）
    - MCP, A2A, Vibe Coding などトレンドのキャッチアップ
    - 他者や他企業の活用事例（Tips）の収集と、自身や自社への還元方法の想起など

## AI駆動開発と協業のポイント
AIとの協働においては、**設計力・伝達力・段階的進行**の3つが成功の鍵となります。<br>
AIとの協働は単なる自動化ではなく、 **AIが理解しやすい形でタスクを定義し、人間が設計を主導する「共同作業」** であると実感しました。<br>
AIにとって曖昧な部分を残さず、具体的・逐次的に伝えることが作業効率および成果物の信頼性向上につながります。<br>

具体的には以下の内容です。

---

### 設計力：ゴールと構造を明確に描く
- ゴール・要件・制約を明確に伝える  
  - プロジェクト・実装機能の目的や背景情報（なぜこの機能が欲しいのか、最終的にどうしたいのか、どうなってほしいのか）
    - 例：「PDF/Excel/画像も対象」「AIで画像内容も判定」「拡張性重視」など
- 設計思想や重視したい観点を伝える  
  - 「疎結合」「責務分離」「保守性」「初学者向けコメント」など、重視したいポイントを明示
    - **適切な専門用語を用いてAIと明確なコミュニケーションを図る**

### 伝達力：情報共有と文脈の維持
- プロジェクト構造やファイル内容を逐次共有  
  - **全体把握**をはじめ、**開発者（ユーザー）が修正・変更などした更新箇所をAIに伝えて随時確認**してもらう（フェーズを設ける）
- プロジェクトまたはファイルの全体像を把握してもらって、プロジェクト・実装機能の目的や背景情報を十分理解してもらう
    - ※もし**前提条件（要件）が変わった場合は随時伝える**
    - ※長時間のやり取りやファイル量が増えると記憶の限界に達するので、**適宜AI側にプロジェクトの目的を再確認してもらうフェーズを設ける**
        - 例：「前にも出したこの設定ファイルを再掲します」「改めて全体構造を整理します」など
- 変更点や新規ファイルも都度明示
    - **開発者（ユーザー）が修正・変更などした更新箇所をAIに伝えて随時確認**してもらう（フェーズを設ける）
    - 上記AIへの更新確認フェーズとともに**関連ドキュメント（READMEや設計、仕様書など）の内容もAIにアップデート（更新）してもらう**
- エラーや実行結果は全文渡す  
  - ログに出たエラー情報やターミナル出力は省略せず、全文をAIに見せる（AIに伝える際、エラー内容は極力省略しない） 

### 段階的進行：ステップごとの合意形成
- **指示は明確**に、**細粒度なタスク依頼**を行う。加えて、**AIとの意思疎通を意識した進捗管理**を行う
- **「ステップバイステップで……」という文言を随時入れてAI自身に思考過程を設けた上で作業を進めて**もらう
- 「この段階で一度確認」「OKなら次へ」と段階的に進行
    - **開発者への確認フェーズ（確認 → Goサイン → タスク実施）を必ず設ける**
- AIが「この方針で進めてよいか？」と聞いてきたら、必ず明確に返答する
    - 開発者への確認フェーズで**AIが提案してきた実装内容・方針を把握しておくことで、ズレがないかチェックできたり、プロジェクト管理しやすくなったりする**メリットがある

### その他
- 出力結果は文法的に正しくても、仕様的に誤っていたり、前提にズレがあることもある
- 特にコード生成やAPI設計では「合っているように見えて誤り」が起きやすいため、人間側で必ずレビューを行う

---

これらに加えて、AIとのやりとりでは、**論理的思考に基づく言語化能力**が不可欠です。<br>
AIには非言語的（ノンバーバル）な意図は伝わらないため、**人間が構造的に考え、明確に伝える力**が必要です。<br>
このスキルはプロンプトエンジニアリングの中核であり、長く活かせる汎用的能力になると感じています。<br>

#### ポイントまとめ
- AIと人間の協働開発は「プロジェクト構造・ファイル内容など情報共有」と「段階的な進行」がカギ
- AIは「明確なゴール（＝何がしたいのか）」「全体像」「具体的なエラー情報」があると最大限力を発揮できる
- 再現性を高めるには、上記のベストプラクティスを意識して進めるのが有効
- ステップバイステップで進行（手戻り防止）
- 設計思想（疎結合・責務分離など）の共有
- 適切な専門用語を用いてAIと明確なコミュニケーションを図る

AIにとって理解しやすい構造と段階的な進行を維持することで、誤解を減らし、再現性を高められます。

## Vibe Coding（雰囲気コーディング）の活用と課題
AIが自律的に高速コーディングしているときに、AIが同じエラーを繰り返す「`pit of death`」という現象も起こり得ます。

#### `pit of death`を減らすには
- タスクのスコープを狭める（タスク粒度の最適化）
- 1つのタスクあたりのステップ数を少なくする
- 生成の特性を知る
  - **現時点**の生成AIは**既存内容の修正が苦手**で、基本的にスクラップ・アンド・ビルドのような生成の仕方（0→1）をするそうなので、ケース・バイ・ケースでプロンプトの内容や実装方針を変えてみたりする

## MCP（Model Context Protocol）によるAI連携
MCPとは、生成AIと外部サービスをつなぐ共通プロトコルです。<br>
AIが外部ツール・API・ファイルシステムなどと連携し、文脈を理解した上で自律的に処理を行えます。<br>
これにより、チャットベースのやりとりを超えた **「行動できるAI」** が実現します。

### MCPの構成と動作概要
MCPホスト, MCPクライアントが「操作指示窓口」で、MCPサーバーが「外部サービスとの連携に必要な中継点」というイメージです。

#### Host
複数のMCPクライアントを統括・管理する中核。<br>
Claude Desktopなどが該当し、MCPの中で**AIの行動環境をホストする役割**を担います。

#### Client
人間の入力や操作を受け取り、AIモデルとの橋渡しを行う層。<br>
リモコン的な役割であり、**ユーザー指示をMCPサーバーに中継**します。

#### Server
外部リソース（GitHub、Figma、DB、APIなど）へのアクセスを提供。<br>
AIはこのサーバーを介して、必要なデータを取得・操作できます。<br>
サーバーはCLI経由で簡単に立ち上げられます。

```bash
# node.jsでの例
npx @modelcontextprotocol/server
```

MCPサーバーの設定は `mcp-config.json` で定義されます。
ここには接続対象、APIキー、権限、リソーススコープなどを指定します。

```json
{
  "servers": {
    "figma": {
      "command": "npx @modelcontextprotocol/server-figma",
      "args": ["--token", "FIGMA_API_KEY"]
    },
    "github": {
      "command": "npx @modelcontextprotocol/server-github",
      "args": ["--token", "GITHUB_PAT"]
    }
  }
}
```

この設定を行うことで、ClaudeなどのAIモデルが外部サービスに対して安全にアクセスできます。<br>

ちなみに、MCPサーバーにはtoolという「そのMCPサーバーができる処理リスト」のようなものがあります。<br>
端的に説明すると、「自分（MCPサーバー）はこんな機能を持っています」とMCPサーバーが情報提供していて、 もし気になるものがあれば「エージェント（MCPクライアント）にそのMCPサーバーを登録して使ってみる」といったものになります。

<details>
<summary>toolについて</summary>

- [Build an MCP server](https://modelcontextprotocol.io/docs/develop/build-server)

```js
server.tool(
  // 第1引数 : MCP経由でAIやクライアントがこのツールを呼び出すときに使う名前
  "get-alerts",
  
  // 第2引数 : このツールが何をするものかをAIに伝えるための説明
  "Get weather alerts for a state",
  
  // 第3引数 : ツールが受け取る「引数のスキーマ定義」(バリデーション)
  {
    state: z.string().length(2).describe("Two-letter state code (e.g. CA, NY)"),
  },
  
  // 第4引数 : 実際にツールが呼び出されたときに実行されるロジック
  async ({ state }) => {
    const stateCode = state.toUpperCase();
    const alertsUrl = `${NWS_API_BASE}/alerts?area=${stateCode}`;
    const alertsData = await makeNWSRequest<AlertsResponse>(alertsUrl);

    if (!alertsData) {
      return {
        content: [
          {
            type: "text",
            text: "Failed to retrieve alerts data",
          },
        ],
      };
    }

    const features = alertsData.features || [];
    if (features.length === 0) {
      return {
        content: [
          {
            type: "text",
            text: `No active alerts for ${stateCode}`,
          },
        ],
      };
    }

    const formattedAlerts = features.map(formatAlert);
    const alertsText = `Active alerts for ${stateCode}:\n\n${formattedAlerts.join("\n")}`;

    return {
      content: [
        {
          type: "text",
          text: alertsText,
        },
      ],
    };
  },
);
```

</details>

### MCPの実践的活用例
- Figma MCP：LPデザイン案をAIが生成し、コンポーネント単位で調整。
- GitHub MCP：リポジトリ内のコード修正やプルリク作成を自動実行。
- Playwright MCP：E2EテストをAIが設計・生成・実行。
- ドキュメントMCP：NotionやConfluenceから設計情報を参照。

これらに共通するのは、**AIがチャットではなく行動で成果を出す**点です。

#### `chrome-devtools-mcp`の事例
`chrome-devtools-mcp`とは、Google公式のDevToolsプロトコルを利用したMCP（Model Context Protocol）サーバーで提供するブラウザ自動化ツールです。

> - GeminiがChromeを直接操作してテストや分析ができる（特にパフォーマンス測定の詳細分析が得意）
> - コンテキスト使用量（トークン使用量）は 類似ツールの Playwright MCP とほぼ同等
> - **`chrome-devtools-mcp`はChrome専用**なので他ブラウザテストには Playwright MCP がベター

1. `Gemini CLI`をインストール<br>
- インストール方法の参考ページ<br>
[「Gemini CLI」のつかいかた ～非エンジニアでも怖くない！ 黒い窓アレルギーを解消しよう](https://forest.watch.impress.co.jp/docs/serial/yaaiwatch/2031780.html)

2. `chrome-devtools-mcp`の設定
対象プロジェクトのルートに`.gemini`というファイルを用意し、その中に`settings.json`を作成
- `.gemini/settings.json`
```json
{
  "mcpServers": {
    "chrome-devtools": {
      "command": "npx",
      "args": ["chrome-devtools-mcp@latest"]
    }
  }
}
```

3. 対象プロジェクトを起点にターミナルで`gemini`コマンド実施
以下コマンドで`chrome-devtools-mcp`を備えた`Gemini CLI`を立ち上げられる。

```bash
gemini
```

あとはプロンプトで指示し、Geminiの返答に応じるだけで進んでいく。
- 雑なプロンプト例：yahooのサイトに行ってコメント数が上位の記事の内容を開き、その要約をして

### 運用上の留意点
- APIキーや認証情報は`.env`などで安全に管理する
- 不要なリソース権限は付与しない
- ローカル環境でも起動可能（オフライン対応）
- MCPサーバーを監視・停止できる仕組みを用意する
- 信用できる制作元のMCPを利用する（無作為にサードパーティMCPを使用しない）

### MCPクライアントとMCPサーバーの通信方式
- `Stdio`（標準入出力）
    - 安全かつ高速。ローカルでの開発や、ネットワークを使いたくないセキュリティ重視のケース向け
    - ネットワークを介さずプログラム同士が直接テキストデータをやり取りする<br><br>

- `Streamable HTTPトランスポート`
    - 大きなデータやリアルタイム性が必要なケース向け
    - 後述の`HTTP+SSE`方式よりもシンプルで柔軟
    - サーバーが単一の`HTTP`エンドポイント（例：`/mcp`）を提供
    - クライアントは`HTTP POST`でリクエストを送信し、（サーバー）レスポンスはストリーミング（分割送信）で返される<br><br>

- `HTTP+SSE`
    - 現在は`Streamable HTTPトランスポート`を利用推奨
    - リアルタイムなデータ配信や、ChatGPTのように文字が徐々に表示されるようなケース向け
    - クライアントがHTTPリクエストでサーバーにアクセスし、サーバーからはSSEで複数のメッセージをストリーミング（サーバーからクライアントへの一方向通信）<br><br>

### A2A（Agent to Agent）とAI同士の連携
A2AはAI同士の通信規格で、MCPが「AIと外部サービス」の橋渡しを担うのに対し、A2Aは「AIとAIの協調」を実現します。
これにより、複数のAIエージェントが役割分担しながら協働可能になります。

## 仕様駆動開発（SDD）
AIは課題解決を最優先に、**自律的に複数ファイルを高速修正**するため、人間が全体を追い切れないこともあります。<br>
Vibe Codingのような人間側で把握しきれない開発手法では、開発の堅牢性や保守・運用など将来性にも大きな影響を与える事態にもなりかねません。<br>
そこで現在この問題を解消するためにAWSの`kiro`やGitHubの`spec-kit`に代表される **仕様駆動開発（SDD）** が注目されています。

- **SSDの中にVibe Coding的な工程要素がある** （水の流れをうまくコントロールするイメージ）<br>
Vibe Coding と SSD はよく相対的な関係性で説明されることがあるものの「**SSDの中にVibe Coding的な工程要素がある**」というのが正確です。<br>
例えば、何も置いていないテーブルに水を垂らした状態をイメージしてみてください。水は自由自在に広がり、人間がコントロールすることは不可能となります。<br>
しかし、テーブルに決まった溝を掘っていたり、パイプのような囲いを置いていたりすれば、水はある程度そのルートに沿って流れていきます。<br>
人間側がルートを設けて水を流す（仕様を伝えてAIが自律的にコーディングする）と、水は期待通り流れていきますし、もしどこかで詰まったり、溢れ出てたりしても人間側でコントロールしやすくなります。<br>
安全・堅実なVibe Codingの実現には、SSDが現状ベターな手法というイメージです。

### スペック / 仕様駆動開発（SDD）
「vibe codingなんて危なっかしくて実務では厳しいよね？」ということでAWSが「まずは仕様を決めて、設計や構成を割り振り、作業フェーズやタスク抽出してから」と段階を踏んでAIに作業してもらおうと提唱して生まれたスタイル（※正確にはこれを実施するAI搭載のIDE：`kiro`）になります。

具体的には以下です。

1. したいことをAIに相談し、AIと壁打ちしながら仕様を決めていく。または人間が事前に整然としたドキュメントを用意しておく
2. 決めた仕様をAI（と人間）が分かりやすいようにAIにまとめてもらって仕様書（`requirements.md`）を用意
3. その仕様書をもとにAIが設計方針や構成、開発フェーズなどプロット（`design.md`）を策定
4. そのプロットに問題なければ、具体的な実装アプローチやタスク割り出し、実行計画（`task.md`）を準備し、それに則って実施（開発）する
5. 人間はAIが実施したタスクを都度レビューして修正・承認を行い開発を進めていく

AWSの`kiro`の後発となりますが、GitHubでも`spec-kit`という仕様駆動開発のオープンソースツールが公開されています。spec-kit では、以下のようなワークフローが紹介されています。

> - Establish project principles:<br>
> `/speckit.constitution`コマンドを使用して、その後のすべての開発のガイドとなるプロジェクトの管理原則と開発ガイドラインを作成します。
> - Create the spec:<br>
> `/speckit.specify`コマンドを使って、何を構築したいのかを説明しましょう。技術スタックではなく、何を、なぜ構築したいのかに焦点を当てましょう。
> - Create a technical implementation plan:<br>
> `/speckit.plan`コマンドを使用して、技術スタックとアーキテクチャの選択肢を指定します。
> - Break down into tasks:<br>
> `/speckit.tasks`コマンドで実装計画から実行可能なタスクリストを作成するために使用します。
> - Execute implementation:<br>
> `/speckit.implement`ですべてのタスクを実行し、計画に従って機能を構築するために使用します。

このように、AIは実行・生成を担い、人間は上流設計・監督を担う体制へと移行しています。

### AIとの協業において重要だと感じたポイントまとめ
- 事前にある程度、環境を用意（構築）しておいた方が効率的
- 上流設計が重要
    - AI は指示の内容が誤っていた場合もそれに合わせたコーディングを行ってしまう（人間側の求める答え・期待に過度に寄り添う姿勢を見せることがある）
    - AI は初期の頃に前提が間違っていた場合、後から修正するのが苦手
    - 長期間のセッションでは、出力内容が段々と劣化していく
- 0 -> 1 は得意だが、既存のものをベースにした修正などは苦手（都度スクラップアンドビルドして生成するため）
- プロンプトは否定形ではなく肯定形で依頼する
- 機能要件（ユーザー管理機能やデータ処理、外部連携の有無など）を細かく伝えることで、AIがより正確な設計を提案してくれる。**作業依頼（タスク）とは異なり、設計部分は詳しければ詳しいほど良い**
- 細粒度のタスクを具体的な指示で依頼する
- 全自動化より「協働」前提で考える
- Vibe Coding や AI を用いたコーディング・プログラミングには前提知識が求められる
    - 例えば、スタイルの修正依頼ひとつ取っても`ドロップシャドウ`や`ブラー`、`ホバー`などの用語を知っていないと適切かつ端的な修正指示ができない
    - 作業依頼に関する補足情報または実装イメージがしっかりしないとうまく指示を出せない<br>
    例えば、`CRUD`機能やデータベースの種類、データベースを用いない簡易なデータ管理方法（`localStorage`）など、**要件定義や技術選定に関わってくるような「何がしたいのか」を具体的に伝達できる知識が必要**だと感じた
- 副次的に論理的思考力を磨くトレーニングにもなる
- **Vibe Coding は知らない記述・記法や未知のライブラリの勉強になるし、その場で聞けるのでキャッチアップ効率も高まる**
- （※Geminiの場合）`Temperature`で成果物の創造性を調整
    - 創造性を高めたい場合は`Temperature`を高め、正確性を重視する場合は下げるなど、生成特性を使い分ける

  
#### 既存プロジェクトのリファクタリングや修正といったケース
例えば、既にいない第三者が開発したものだったり、ドキュメント不足のプロジェクトだったり、慣れない言語やフレームワークを使ったプロジェクトだったりする場合には以下を意識してみてください。

- 情報・状況把握して、それらをAIに投げて壁打ちしながら仮説出し及びコード改修を進める
- AIと協業することで言語やフレームワークをはじめ、プロジェクトの構造理解も捗るので作業効率が良い
- タスク選定からフェーズ構築をはじめ、壁打ち時は`Ask`モードで進めてAIの自律行動を抑制し、実際の作業開始時に`Agent`モードに切り替える
- AI自身に対応箇所（タスク）を選定してもらい、作業フェーズも構築してもらう
    - フェーズを分けていないと壁打ちを続ける内に情報が埋もれたり、どうしても散らかったりしてしまうが、分けておくことで互いに情報整理と把握がしやすくなる
    - タスク実行前のフェーズで壁打ちして、コード理解やプロジェクト構造理解をしっかり深められないと次のタスク実施の判断もしづらくなる
- プロンプトで作業に対する「（汎用的な）制約」を設ける
```bash
- まずはプロジェクトの全体像を把握して、どんなサイト・サービスかを言語化して
- ステップバイステップで作業フェーズを考えて、フェーズごとのタスクを想定および選定して
- フェーズが変わるタイミングやタスク実施時は随時確認して
- 不明点や疑問点があれば作業を止めて聞いて
```

## まとめ
冒頭で述べたように、これは筆者が業務や個人開発などを通じて得た所感・情報をまとめたドキュメントです。
包括的な内容ではないものの、要所要所で活用できる部分もあるのではと記事にしました。

今後も当記事にキャッチアップ内容を適宜更新していきます。
ここまで読んでいただき、ありがとうございました。

## 参考
順不同です。

https://forest.watch.impress.co.jp/docs/serial/yaaiwatch/2031780.html

https://qiita.com/kissy24/items/1dce568e4a22ef5ada8a

https://zenn.dev/dyoshikawa/articles/developers-still-need-to-understand-ais-code

https://zenn.dev/portalkeyinc/articles/b0392e17ad2116
